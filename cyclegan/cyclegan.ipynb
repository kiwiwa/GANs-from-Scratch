{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz80rPMZKObK"
   },
   "source": [
    "# Aquire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48745
    },
    "colab_type": "code",
    "id": "8TfuN-3v21sL",
    "outputId": "1899d2db-50bd-4571-c612-fb601ead25e1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "FILE=horse2zebra\n",
    "\n",
    "if [[ $FILE != \"ae_photos\" && $FILE != \"apple2orange\" && $FILE != \"summer2winter_yosemite\" &&  $FILE != \"horse2zebra\" && $FILE != \"monet2photo\" && $FILE != \"cezanne2photo\" && $FILE != \"ukiyoe2photo\" && $FILE != \"vangogh2photo\" && $FILE != \"maps\" && $FILE != \"cityscapes\" && $FILE != \"facades\" && $FILE != \"iphone2dslr_flower\" && $FILE != \"ae_photos\" ]]; then\n",
    "    echo \"Available datasets are: apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "URL=https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/$FILE.zip\n",
    "mkdir ./datasets/\n",
    "ZIP_FILE=./datasets/$FILE.zip\n",
    "TARGET_DIR=./datasets/$FILE/\n",
    "wget -N $URL -O $ZIP_FILE\n",
    "mkdir $TARGET_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "FILE='horse2zebra'\n",
    "zip_ref = zipfile.ZipFile('./datasets/' + FILE + '.zip', 'r')\n",
    "zip_ref.extractall('./datasets/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAu_qett4H4v"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufcX0A2Y4J_t"
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "channels = 3\n",
    "ngf = 32\n",
    "ndf = 64\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1\n",
    "lambda_X = 10\n",
    "lambda_Y = 10\n",
    "lambda_identity_X = 0.5\n",
    "lambda_identity_Y = 0.5\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "\n",
    "mean_init = 0.0\n",
    "std_init = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "roIYTK_rvNJP",
    "outputId": "58efce5c-2b03-451b-b493-4ed3fcad76e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda.\n"
     ]
    }
   ],
   "source": [
    "# Cuda stuff\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device is \" + str(device) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPy-hIOP43Ux"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        block = [nn.ReflectionPad2d(1),\n",
    "                 nn.Conv2d(c, c, 3, 1, 0),\n",
    "                 nn.InstanceNorm2d(c),\n",
    "                 nn.ReLU(),\n",
    "                 nn.ReflectionPad2d(1),\n",
    "                 nn.Conv2d(c, c, 3, 1, 0),\n",
    "                 nn.InstanceNorm2d(c)]\n",
    "        \n",
    "        self.block = nn.Sequential(*block)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SijtRQW8aGv"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Encoding\n",
    "        model = []\n",
    "        model += [nn.ReflectionPad2d(4),\n",
    "                  nn.Conv2d(3, ngf, 9, 1, 0),\n",
    "                  nn.InstanceNorm2d(ngf),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.Conv2d(ngf, ngf*2, 3, 2, 1),\n",
    "                  nn.InstanceNorm2d(ngf*2),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.Conv2d(ngf*2, ngf*4, 3, 2, 1),\n",
    "                  nn.InstanceNorm2d(ngf*4),\n",
    "                  nn.ReLU()]\n",
    "        \n",
    "        # Transformation\n",
    "        for i in range(6):\n",
    "            model += [ResidualBlock(ngf*4)]\n",
    "        \n",
    "        # Decoding\n",
    "        model += [nn.ConvTranspose2d(ngf*4, ngf*2, 3, 2, 1, output_padding=1),\n",
    "                  nn.InstanceNorm2d(ngf*2),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.ConvTranspose2d(ngf*2, ngf, 3, 2, 1, output_padding=1),\n",
    "                  nn.InstanceNorm2d(ngf),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.ReflectionPad2d(4),\n",
    "                  nn.Conv2d(ngf, 3, 9, 1, 0),\n",
    "                  nn.Tanh()]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScqGWgOGTCnx"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        model = []\n",
    "        model += [nn.Conv2d(3, ndf, 4, 2, 1),\n",
    "                  nn.LeakyReLU(0.2)]\n",
    "        \n",
    "        in_channels = ndf\n",
    "        out_channels = ndf*2\n",
    "        for i in range(2):\n",
    "            model += [nn.Conv2d(in_channels, out_channels, 4, 2, 1),\n",
    "                      nn.InstanceNorm2d(out_channels),\n",
    "                      nn.LeakyReLU(0.2)]\n",
    "            in_channels = out_channels\n",
    "            out_channels = out_channels * 2\n",
    "\n",
    "        model += [nn.Conv2d(in_channels, out_channels, 4, 1, 1),\n",
    "                  nn.InstanceNorm2d(out_channels),\n",
    "                  nn.LeakyReLU(0.2)]\n",
    "        \n",
    "        model += [nn.Conv2d(out_channels, 1, 4, 1, 1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQZCce-PjX3Z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "class UnallignedDataset(Dataset):\n",
    "    def __init__(self, root, transform, phase='train'):\n",
    "        dir_A = os.path.join(root, phase + 'A')\n",
    "        dir_B = os.path.join(root, phase + 'B')\n",
    "        \n",
    "        self.A_paths = [os.path.join(dir_A, f) for f in os.listdir(dir_A)]\n",
    "        self.B_paths = [os.path.join(dir_B, f) for f in os.listdir(dir_B)]\n",
    "        self.A_size = len(self.A_paths)\n",
    "        self.B_size = len(self.B_paths)\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        B_path = self.B_paths[random.randint(0, self.B_size - 1)]\n",
    "        \n",
    "        A_img = Image.open(A_path).convert('RGB')\n",
    "        B_img = Image.open(B_path).convert('RGB')\n",
    "\n",
    "        A = self.transform(A_img)\n",
    "        B = self.transform(B_img)\n",
    "        return A, B\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(self.A_size, self.B_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHht4nVj8n7F"
   },
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        self.images = []\n",
    "        \n",
    "    def get(self, img):\n",
    "        if len(self.images) < self.pool_size:\n",
    "            self.images.append(img)\n",
    "            return img\n",
    "        else:\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                idx = random.randint(0, self.pool_size-1)\n",
    "                tmp = self.images[idx]\n",
    "                self.images[idx] = img\n",
    "                return tmp\n",
    "            else:\n",
    "                return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_nWsNBQKhGz"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "il5CP_fDXnay"
   },
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "F = Generator().to(device)\n",
    "D_X = Discriminator().to(device)\n",
    "D_Y = Discriminator().to(device)\n",
    "G.weight_init(mean_init, std_init)\n",
    "F.weight_init(mean_init, std_init)\n",
    "D_X.weight_init(mean_init, std_init)\n",
    "D_Y.weight_init(mean_init, std_init)\n",
    "G.train()\n",
    "F.train()\n",
    "D_X.train()\n",
    "D_Y.train()\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(img_size), transforms.CenterCrop(img_size), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('datasets/horse2zebra', transform), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('datasets/horse2zebra', transform, phase='test'), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=2)\n",
    "\n",
    "X_pool = ImagePool(50)\n",
    "Y_pool = ImagePool(50)\n",
    "\n",
    "mse_criterion = nn.MSELoss()\n",
    "l1_criterion = nn.L1Loss()\n",
    "\n",
    "GF_optimizer = torch.optim.Adam(list(G.parameters()) + list(F.parameters()), lr=lr, betas=betas)\n",
    "D_X_optimizer = torch.optim.Adam(D_X.parameters(), lr=lr, betas=betas)\n",
    "D_Y_optimizer = torch.optim.Adam(D_Y.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "GF_scheduler = StepLR(GF_optimizer, 1, lr/100.0)\n",
    "D_X_scheduler = StepLR(D_X_optimizer, 1, lr/100.0)\n",
    "D_Y_scheduler = StepLR(D_Y_optimizer, 1, lr/100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ReflectionPad2d-1          [-1, 3, 264, 264]               0\n",
      "            Conv2d-2         [-1, 32, 256, 256]           7,808\n",
      "    InstanceNorm2d-3         [-1, 32, 256, 256]               0\n",
      "              ReLU-4         [-1, 32, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]          18,496\n",
      "    InstanceNorm2d-6         [-1, 64, 128, 128]               0\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8          [-1, 128, 64, 64]          73,856\n",
      "    InstanceNorm2d-9          [-1, 128, 64, 64]               0\n",
      "             ReLU-10          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-11          [-1, 128, 66, 66]               0\n",
      "           Conv2d-12          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-13          [-1, 128, 64, 64]               0\n",
      "             ReLU-14          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-15          [-1, 128, 66, 66]               0\n",
      "           Conv2d-16          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-17          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-18          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-19          [-1, 128, 66, 66]               0\n",
      "           Conv2d-20          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-21          [-1, 128, 64, 64]               0\n",
      "             ReLU-22          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-23          [-1, 128, 66, 66]               0\n",
      "           Conv2d-24          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-25          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-26          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-27          [-1, 128, 66, 66]               0\n",
      "           Conv2d-28          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-29          [-1, 128, 64, 64]               0\n",
      "             ReLU-30          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-31          [-1, 128, 66, 66]               0\n",
      "           Conv2d-32          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-33          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-34          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-35          [-1, 128, 66, 66]               0\n",
      "           Conv2d-36          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-37          [-1, 128, 64, 64]               0\n",
      "             ReLU-38          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-39          [-1, 128, 66, 66]               0\n",
      "           Conv2d-40          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-41          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-42          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-43          [-1, 128, 66, 66]               0\n",
      "           Conv2d-44          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-45          [-1, 128, 64, 64]               0\n",
      "             ReLU-46          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-47          [-1, 128, 66, 66]               0\n",
      "           Conv2d-48          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-49          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-50          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-51          [-1, 128, 66, 66]               0\n",
      "           Conv2d-52          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-53          [-1, 128, 64, 64]               0\n",
      "             ReLU-54          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-55          [-1, 128, 66, 66]               0\n",
      "           Conv2d-56          [-1, 128, 64, 64]         147,584\n",
      "   InstanceNorm2d-57          [-1, 128, 64, 64]               0\n",
      "    ResidualBlock-58          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-59         [-1, 64, 128, 128]          73,792\n",
      "   InstanceNorm2d-60         [-1, 64, 128, 128]               0\n",
      "             ReLU-61         [-1, 64, 128, 128]               0\n",
      "  ConvTranspose2d-62         [-1, 32, 256, 256]          18,464\n",
      "   InstanceNorm2d-63         [-1, 32, 256, 256]               0\n",
      "             ReLU-64         [-1, 32, 256, 256]               0\n",
      "  ReflectionPad2d-65         [-1, 32, 264, 264]               0\n",
      "           Conv2d-66          [-1, 3, 256, 256]           7,779\n",
      "             Tanh-67          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 1,971,203\n",
      "Trainable params: 1,971,203\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 372.66\n",
      "Params size (MB): 7.52\n",
      "Estimated Total Size (MB): 380.93\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
      "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
      "            Conv2d-3          [-1, 128, 64, 64]         131,200\n",
      "    InstanceNorm2d-4          [-1, 128, 64, 64]               0\n",
      "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
      "            Conv2d-6          [-1, 256, 32, 32]         524,544\n",
      "    InstanceNorm2d-7          [-1, 256, 32, 32]               0\n",
      "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
      "            Conv2d-9          [-1, 512, 31, 31]       2,097,664\n",
      "   InstanceNorm2d-10          [-1, 512, 31, 31]               0\n",
      "        LeakyReLU-11          [-1, 512, 31, 31]               0\n",
      "           Conv2d-12            [-1, 1, 30, 30]           8,193\n",
      "================================================================\n",
      "Total params: 2,764,737\n",
      "Trainable params: 2,764,737\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 45.27\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 56.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(G, (3, 256, 256))\n",
    "summary(D_X, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "colab_type": "code",
    "id": "61scdU94hpqL",
    "outputId": "de6f3edc-ccd2-4a9c-e4e8-fd86cce093bf"
   },
   "outputs": [],
   "source": [
    "def mean(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "# Create tensorboardX writer\n",
    "writer = SummaryWriter('logs')\n",
    "# Prepare some test data, 5 of each kind\n",
    "test_data = [(x.to(device), y.to(device)) for i, (x, y) in enumerate(test_loader) if i<5]\n",
    "\n",
    "# Define target vectors\n",
    "fake_target = 0.0\n",
    "real_target = 1.0\n",
    "for epoch in range(epochs):\n",
    "    G_gan_loss_epoch = []\n",
    "    G_cycle_loss_epoch = []\n",
    "    G_ident_loss_epoch = []\n",
    "    D_X_gan_loss_epoch = []\n",
    "    \n",
    "    # Linear lr decay\n",
    "    if epoch > 99:\n",
    "        GF_scheduler.step()\n",
    "        D_X_scheduler.step()\n",
    "        D_Y_scheduler.step()\n",
    "        \n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        #########################################################\n",
    "        # Update generators\n",
    "        #########################################################\n",
    "        GF_optimizer.zero_grad()\n",
    "        \n",
    "        # Translate from X to Y, check D_Y output\n",
    "        G_out = G(X)\n",
    "        D_Y_out = D_Y(G_out.detach())\n",
    "        G_gan_loss = mse_criterion(D_Y_out, torch.ones_like(D_Y_out).to(device))\n",
    "        \n",
    "        # Translate from Y to X, check D_X output\n",
    "        F_out = F(Y)\n",
    "        D_X_out = D_X(F_out.detach())\n",
    "        F_gan_loss = mse_criterion(D_X_out, torch.ones_like(D_X_out).to(device))\n",
    "        \n",
    "        # Translate from X to Y to X, check reconstruction error\n",
    "        X_recon = F(G_out)\n",
    "        G_cycle_loss = l1_criterion(X_recon, X) * lambda_X\n",
    "        \n",
    "        # Translate from Y to X to Y, check reconstruction error\n",
    "        Y_recon = G(F_out)\n",
    "        F_cycle_loss = l1_criterion(Y_recon, Y) * lambda_Y\n",
    "        \n",
    "        # Translate a picture from Y from X to Y, should be Y\n",
    "        Y_ident = G(Y)\n",
    "        G_ident_loss = l1_criterion(Y_ident, Y) * lambda_identity_X * lambda_X\n",
    "        \n",
    "        # Translate a picture from X from Y to X, should be X\n",
    "        X_ident = F(X)\n",
    "        F_ident_loss = l1_criterion(X_ident, X) * lambda_identity_X * lambda_Y\n",
    "        \n",
    "        GF_loss = G_cycle_loss + F_cycle_loss + G_ident_loss + F_ident_loss + G_gan_loss + F_gan_loss\n",
    "        GF_loss.backward()\n",
    "        GF_optimizer.step()\n",
    "        \n",
    "        #########################################################\n",
    "        # Update discriminators\n",
    "        # D_Y, minimize L_D_Y = E_y (D(y) - 1) ^2 + E_x (D(x))^2\n",
    "        #########################################################\n",
    "        D_Y_optimizer.zero_grad()\n",
    "        \n",
    "        # Test D_Y with fake and real input\n",
    "        G_out = Y_pool.get(G_out)\n",
    "        D_Y_out_fake = D_Y(G_out.detach())\n",
    "        D_Y_out_real = D_Y(Y)\n",
    "        # Calculate loss\n",
    "        D_Y_loss_fake = mse_criterion(D_Y_out_fake, torch.zeros_like(D_Y_out_fake).to(device))\n",
    "        D_Y_loss_real = mse_criterion(D_Y_out_real, torch.ones_like(D_Y_out_real).to(device))\n",
    "        D_Y_gan_loss = (D_Y_loss_real + D_Y_loss_fake)*0.5\n",
    "        \n",
    "        D_Y_gan_loss.backward()\n",
    "        D_Y_optimizer.step()\n",
    "        \n",
    "        #########################################################\n",
    "        # D_X, minimize L_D_X = E_x (D(x) - 1) ^2 + E_y (D(y))^2\n",
    "        #########################################################\n",
    "        D_X_optimizer.zero_grad()\n",
    "        \n",
    "        # Test D_X with fake and real input\n",
    "        F_out = X_pool.get(F_out)\n",
    "        D_X_out_fake = D_X(F_out.detach())\n",
    "        D_X_out_real = D_X(X)\n",
    "        # Calculate loss\n",
    "        D_X_loss_fake = mse_criterion(D_X_out_fake, torch.zeros_like(D_X_out_fake).to(device))\n",
    "        D_X_loss_real = mse_criterion(D_X_out_real, torch.ones_like(D_X_out_real).to(device))\n",
    "        D_X_gan_loss = (D_X_loss_real + D_X_loss_fake)*0.5\n",
    "        \n",
    "        D_X_gan_loss.backward()\n",
    "        D_X_optimizer.step()\n",
    "        \n",
    "        # Save losses\n",
    "        G_gan_loss_epoch.append(G_gan_loss.item())\n",
    "        G_cycle_loss_epoch.append(G_cycle_loss.item())\n",
    "        G_ident_loss_epoch.append(G_ident_loss.item())\n",
    "        D_X_gan_loss_epoch.append(D_X_gan_loss.item())\n",
    "        \n",
    "        # Do some test output every 100 batches\n",
    "        if i % 100 == 0:\n",
    "            print('\\rEpoch [%d/%d], Batch [%d/%d]' % (epoch+1, epochs, i, len(train_loader)), end='')\n",
    "            \n",
    "            image_tensor = None\n",
    "            # Generate test outputs\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                G.eval()\n",
    "                F.eval()\n",
    "                for X, Y in test_data:\n",
    "                    G_out = G(X)\n",
    "                    F_out = F(Y)\n",
    "                    if image_tensor is None:\n",
    "                        image_tensor = torch.cat((X, G_out, Y, F_out), 0)\n",
    "                    else:\n",
    "                        image_tensor = torch.cat((image_tensor, X, G_out, Y, F_out), 0)\n",
    "                G.train()\n",
    "                F.train()\n",
    "            image = make_grid(image_tensor, nrow=4, padding=2, normalize=True)\n",
    "            writer.add_image('test_images', image, i+epoch*len(train_loader))\n",
    "    \n",
    "    # Calculate mean\n",
    "    G_gan_loss_epoch = mean(G_gan_loss_epoch)\n",
    "    G_cycle_loss_epoch = mean(G_cycle_loss_epoch)\n",
    "    G_ident_loss_epoch = mean(G_ident_loss_epoch)\n",
    "    G_loss_epoch = G_gan_loss_epoch + G_cycle_loss_epoch + G_ident_loss_epoch\n",
    "    D_X_gan_loss_epoch = mean(D_X_gan_loss_epoch)\n",
    "\n",
    "    # Put losses into log\n",
    "    writer.add_scalar('G_gan_loss', G_gan_loss_epoch, epoch)\n",
    "    writer.add_scalar('G_cycle_loss', G_cycle_loss_epoch, epoch)\n",
    "    writer.add_scalar('G_ident_loss', G_ident_loss_epoch, epoch)\n",
    "    writer.add_scalar('G_loss', G_loss_epoch, epoch)\n",
    "    writer.add_scalar('D_X_loss', D_X_gan_loss_epoch, epoch)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), 'G.pt')\n",
    "torch.save(F.state_dict(), 'F.pt')\n",
    "torch.save(D_X.state_dict(), 'D_X.pt')\n",
    "torch.save(D_Y.state_dict(), 'D_Y.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cyclegan.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
